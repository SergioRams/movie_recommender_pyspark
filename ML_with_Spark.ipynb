{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie recomender system using PySpark\n",
    "under construction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# spark libs.\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import lower, col\n",
    "# spark datatypes\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# check Spark UI from \n",
    "# http://localhost:4040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating spark session and setting up number of partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating spark local machine session.\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# setup 5 partitions since data is not \"big-data\", and is running locally.\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading movie data from CSV files into Spark DataFrames.\n",
    "We could let Spark <b>infer</b> the schema but in this case we do the <b>explicit</b> datyping as good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schemas (DataFrame's Metadata) to load CSV into Spark DataFrame\n",
    "\n",
    "# USER SCHEMA\n",
    "# user id | age | gender | occupation | zip code\n",
    "user_schema =  StructType([\n",
    "                    StructField(\"user_id\", ShortType(), False), # False = not null\n",
    "                    StructField(\"age\", ByteType(), True),\n",
    "                    StructField(\"gender\", StringType(), True),\n",
    "                    StructField(\"occupation\", StringType(), True),\n",
    "                    StructField(\"zip\", StringType(), True),\n",
    "                ])\n",
    "\n",
    "# GENRE SCHEMA\n",
    "# genre | genre_id\n",
    "genre_schema = StructType([\n",
    "                    StructField(\"genre\", StringType(), True),\n",
    "                    StructField(\"genre_id\", ShortType(), False), # False = not null\n",
    "                ])\n",
    "\n",
    "# MOVIE SCHEMA \n",
    "# movie id | movie title | release date | video release date | IMDb URL | unknown | Action | \n",
    "# Adventure | Animation | Children's | Comedy | Crime | Documentary | Drama | Fantasy |\n",
    "# Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western |\n",
    "movie_schema = StructType([\n",
    "                    StructField(\"movie_id\", ShortType(), False), # False = not null\n",
    "                    StructField(\"title\", StringType(), True),\n",
    "                    StructField(\"release_date\", StringType(), True), # format: 01-Jan-1995\n",
    "                    StructField(\"video_date\", StringType(), True), # format: 01-Jan-1995\n",
    "                    StructField(\"url\", StringType(), True),\n",
    "                    StructField(\"unknown\", ByteType(), True),\n",
    "                    StructField(\"action\", ByteType(), True),\n",
    "                    StructField(\"adventure\", ByteType(), True),\n",
    "                    StructField(\"animation\", ByteType(), True),\n",
    "                    StructField(\"children\", ByteType(), True),\n",
    "                    StructField(\"comedy\", ByteType(), True),\n",
    "                    StructField(\"crime\", ByteType(), True),\n",
    "                    StructField(\"documentary\", ByteType(), True),\n",
    "                    StructField(\"drama\", ByteType(), True),\n",
    "                    StructField(\"fantasy\", ByteType(), True),\n",
    "                    StructField(\"film_noir\", ByteType(), True),\n",
    "                    StructField(\"horror\", ByteType(), True),\n",
    "                    StructField(\"musical\", ByteType(), True),\n",
    "                    StructField(\"mystery\", ByteType(), True),\n",
    "                    StructField(\"romance\", ByteType(), True),\n",
    "                    StructField(\"sci_fi\", ByteType(), True),\n",
    "                    StructField(\"thriller\", ByteType(), True),\n",
    "                    StructField(\"war\", ByteType(), True),\n",
    "                    StructField(\"western\", ByteType(), True),\n",
    "            ])\n",
    "\n",
    "# USER-MOVIE RATINGS SCHEMA\n",
    "# user id | item id | rating | timestamp\n",
    "rating_schema = StructType([\n",
    "                    StructField(\"user_id\", ShortType(), False), # False = not null\n",
    "                    StructField(\"movie_id\", ShortType(), False),\n",
    "                    StructField(\"rating\", ShortType(), False),\n",
    "                    StructField(\"timestamp\", StringType(), True),\n",
    "                    #StructField(\"timestamp\", TimestampType(), True), \n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, name, schema, delimiter=','):\n",
    "    \"\"\"\n",
    "    Takes in the path, name and schema of the CSV\n",
    "    Returns a Spark DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    fullpath = path + name\n",
    "\n",
    "    # read CSV using the provided schema.\n",
    "    dataframe = spark.read.format(\"csv\")\\\n",
    "        .schema(schema)\\\n",
    "        .option(\"header\", \"false\")\\\n",
    "        .option(\"delimiter\", delimiter)\\\n",
    "        .option(\"mode\", \"FAILFAST\")\\\n",
    "        .load(fullpath)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# load CSVs into Spark.\n",
    "user_df = read_csv( path='ml-100k/', name='u.user', schema=user_schema, delimiter='|' )\n",
    "genre_df = read_csv( path='ml-100k/', name='u.genre', schema=genre_schema, delimiter='|' )\n",
    "movie_df = read_csv( path='ml-100k/', name='u.item', schema=movie_schema, delimiter='|' )\n",
    "rating_df = read_csv( path='ml-100k/', name='u.data', schema=rating_schema, delimiter='\\t' )\n",
    "\n",
    "# create Spark tables to enable use of SQL.\n",
    "user_df.createOrReplaceTempView('user_df')\n",
    "genre_df.createOrReplaceTempView('genre_df')\n",
    "movie_df.createOrReplaceTempView('movie_df')\n",
    "rating_df.createOrReplaceTempView('rating_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: short (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- video_date: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- unknown: byte (nullable = true)\n",
      " |-- action: byte (nullable = true)\n",
      " |-- adventure: byte (nullable = true)\n",
      " |-- animation: byte (nullable = true)\n",
      " |-- children: byte (nullable = true)\n",
      " |-- comedy: byte (nullable = true)\n",
      " |-- crime: byte (nullable = true)\n",
      " |-- documentary: byte (nullable = true)\n",
      " |-- drama: byte (nullable = true)\n",
      " |-- fantasy: byte (nullable = true)\n",
      " |-- film_noir: byte (nullable = true)\n",
      " |-- horror: byte (nullable = true)\n",
      " |-- musical: byte (nullable = true)\n",
      " |-- mystery: byte (nullable = true)\n",
      " |-- romance: byte (nullable = true)\n",
      " |-- sci_fi: byte (nullable = true)\n",
      " |-- thriller: byte (nullable = true)\n",
      " |-- war: byte (nullable = true)\n",
      " |-- western: byte (nullable = true)\n",
      "\n",
      "Total Movies:1682\n"
     ]
    }
   ],
   "source": [
    "# checking movie DataFrame datatypes.\n",
    "movie_df.printSchema()\n",
    "print(f'Total Movies:{movie_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|      1| 24|     M|technician|85711|\n",
      "|      2| 53|     F|     other|94043|\n",
      "|      3| 23|     M|    writer|32067|\n",
      "|      4| 24|     M|technician|43537|\n",
      "|      5| 33|     F|     other|15213|\n",
      "+-------+---+------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total Users:943\n"
     ]
    }
   ],
   "source": [
    "# print top 5 rows nicely with show()\n",
    "user_df.show(5)\n",
    "print(f'Total Users:{user_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(genre='unknown', genre_id=0), Row(genre='Action', genre_id=1), Row(genre='Adventure', genre_id=2), Row(genre='Animation', genre_id=3), Row(genre=\"Children's\", genre_id=4)]\n",
      "\n",
      "Total genres:19\n"
     ]
    }
   ],
   "source": [
    "# get top 5 genre rows with take()\n",
    "print(genre_df.take(5))\n",
    "print(f'\\nTotal genres:{genre_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(movie_id=1, title='Toy Story (1995)', release_date='01-Jan-1995', video_date=None, url='http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)', unknown=0, action=0, adventure=0, animation=1, children=1, comedy=1, crime=0, documentary=0, drama=0, fantasy=0, film_noir=0, horror=0, musical=0, mystery=0, romance=0, sci_fi=0, thriller=0, war=0, western=0), Row(movie_id=2, title='GoldenEye (1995)', release_date='01-Jan-1995', video_date=None, url='http://us.imdb.com/M/title-exact?GoldenEye%20(1995)', unknown=0, action=1, adventure=1, animation=0, children=0, comedy=0, crime=0, documentary=0, drama=0, fantasy=0, film_noir=0, horror=0, musical=0, mystery=0, romance=0, sci_fi=0, thriller=1, war=0, western=0)]\n",
      "\n",
      "Total movies:1682\n"
     ]
    }
   ],
   "source": [
    "# get top movies rows.\n",
    "print(movie_df.take(2))\n",
    "print(f'\\nTotal movies:{movie_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+\n",
      "|user_id|movie_id|rating|timestamp|\n",
      "+-------+--------+------+---------+\n",
      "|    196|     242|     3|881250949|\n",
      "|    186|     302|     3|891717742|\n",
      "|     22|     377|     1|878887116|\n",
      "|    244|      51|     2|880606923|\n",
      "|    166|     346|     1|886397596|\n",
      "+-------+--------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Total ratings:100000\n"
     ]
    }
   ],
   "source": [
    "# print top 5 ratings.\n",
    "rating_df.show(5)\n",
    "print(f'\\nTotal ratings:{rating_df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|    161| 50|     M|    lawyer|55104|\n",
      "|    205| 47|     M|    lawyer|06371|\n",
      "|    419| 37|     M|    lawyer|43215|\n",
      "|    339| 35|     M|    lawyer|37901|\n",
      "|    680| 33|     M|    lawyer|90405|\n",
      "|    125| 30|     M|    lawyer|22202|\n",
      "|    365| 29|     M|    lawyer|20009|\n",
      "|    846| 27|     M|    lawyer|47130|\n",
      "+-------+---+------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing some SQL on a Spark table.\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * \n",
    "    FROM user_df \n",
    "    WHERE occupation = 'lawyer' AND\n",
    "        age BETWEEN 25 AND 50 AND\n",
    "        gender = 'M'\n",
    "    ORDER BY age DESC\n",
    "    \"\"\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making some adjustmens to genre names, lowecase and replacing dash for underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|      genre|genre_id|\n",
      "+-----------+--------+\n",
      "|    unknown|       0|\n",
      "|     action|       1|\n",
      "|  adventure|       2|\n",
      "|  animation|       3|\n",
      "| children's|       4|\n",
      "|     comedy|       5|\n",
      "|      crime|       6|\n",
      "|documentary|       7|\n",
      "|      drama|       8|\n",
      "|    fantasy|       9|\n",
      "|  film-noir|      10|\n",
      "|     horror|      11|\n",
      "|    musical|      12|\n",
      "|    mystery|      13|\n",
      "|    romance|      14|\n",
      "|     sci-fi|      15|\n",
      "|   thriller|      16|\n",
      "|        war|      17|\n",
      "|    western|      18|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_df = genre_df.withColumn('genre', lower(col('genre')))\n",
    "genre_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 unknown\n",
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|     267|\n",
      "|    1373|\n",
      "+--------+\n",
      "\n",
      "1 action\n",
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|       2|\n",
      "|       4|\n",
      "|      17|\n",
      "|      21|\n",
      "|      22|\n",
      "|      24|\n",
      "|      27|\n",
      "|      28|\n",
      "|      29|\n",
      "|      33|\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "2 adventure\n",
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|       2|\n",
      "|      21|\n",
      "|      24|\n",
      "|      29|\n",
      "|      35|\n",
      "|      50|\n",
      "|      62|\n",
      "|      78|\n",
      "|      82|\n",
      "|      97|\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "3 animation\n",
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|       1|\n",
      "|      71|\n",
      "|      95|\n",
      "|      99|\n",
      "|     101|\n",
      "|     102|\n",
      "|     103|\n",
      "|     114|\n",
      "|     169|\n",
      "|     189|\n",
      "+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "4 children's\n"
     ]
    },
    {
     "ename": "ParseException",
     "evalue": "\"\\nmismatched input ''' expecting <EOF>(line 4, pos 22)\\n\\n== SQL ==\\n\\n        SELECT movie_id\\n        FROM movie_df\\n        WHERE children's = 1\\n----------------------^^^\\n        \\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o21.sql.\n: org.apache.spark.sql.catalyst.parser.ParseException: \nmismatched input ''' expecting <EOF>(line 4, pos 22)\n\n== SQL ==\n\n        SELECT movie_id\n        FROM movie_df\n        WHERE children's = 1\n----------------------^^^\n        \n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:241)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:117)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:48)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:69)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8efc53bb14a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mFROM\u001b[0m \u001b[0mmovie_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mWHERE\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m     13\u001b[0m     ).show(10)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.streaming.StreamingQueryException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStreamingQueryException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseException\u001b[0m: \"\\nmismatched input ''' expecting <EOF>(line 4, pos 22)\\n\\n== SQL ==\\n\\n        SELECT movie_id\\n        FROM movie_df\\n        WHERE children's = 1\\n----------------------^^^\\n        \\n\""
     ]
    }
   ],
   "source": [
    "# Since Movie table is not normalized to second normal form, we need can fix that to make it easier to query.\n",
    "# First we create a movie-genre table, which is a many to many relationship.\n",
    "\n",
    "for genre in genre_df.take(1000):\n",
    "    print(genre.genre_id, genre.genre)\n",
    "    \n",
    "    spark.sql(\n",
    "        f\"\"\"\n",
    "        SELECT movie_id\n",
    "        FROM movie_df\n",
    "        WHERE {genre.genre} = 1\n",
    "        \"\"\"\n",
    "    ).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
